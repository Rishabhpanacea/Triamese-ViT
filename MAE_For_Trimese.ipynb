{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de610f97-ae64-4aae-bc43-dc7caba665e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from Models.MultiViewViT import MultiViewViT\n",
    "from load_data import IMG_Folder\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14d458-c904-48f8-a74d-f24e6896c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(w):\n",
    "    classname = w.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        if hasattr(w, 'weight'):\n",
    "            # nn.init.kaiming_normal_(w.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(w.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "                nn.init.constant_(w.bias, 0)\n",
    "    if classname.find('Linear') != -1:\n",
    "        if hasattr(w, 'weight'):\n",
    "            torch.nn.init.xavier_normal_(w.weight)\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        if hasattr(w, 'weight') and w.weight is not None:\n",
    "            nn.init.constant_(w.weight, 1)\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "            nn.init.constant_(w.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588749c1-3896-4218-a30a-f92717a7eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = MultiViewViT(\n",
    "    image_sizes=[(91, 109), (91, 91), (109, 91)],\n",
    "    patch_sizes=[(7, 7), (7, 7), (7, 7)],\n",
    "    num_channals=[91, 109, 91],\n",
    "    vit_args={\n",
    "        'emb_dim': 768, 'mlp_dim': 3072, 'num_heads': 12,\n",
    "        'num_layers': 12, 'num_classes': 1,\n",
    "        'dropout_rate': 0.1, 'attn_dropout_rate': 0.0\n",
    "    },\n",
    "    mlp_dims=[3, 128, 256, 512, 1024, 512, 256, 128, 1]\n",
    ")\n",
    "model.apply(weights_init)\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "# Load checkpoint\n",
    "CheckpointPath = r'C:\\Users\\Rishabh\\training_output_metricsMulti_VIT_best_model.pth.tar'\n",
    "checkpoint = torch.load(CheckpointPath, map_location=\"cpu\")\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383799be-e00b-47fb-8f24-b6385fc1b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CheckpointPath = r'C:\\Users\\Rishabh\\trainingMulti_VIT_best_model.pth.tar'\n",
    "CSVPath = r'C:\\Users\\Rishabh\\Documents\\TransBTS\\IXI.xlsx'\n",
    "DataFolder = r'C:\\Users\\Rishabh\\Documents\\TrimeseData'\n",
    "device = \"cpu\"\n",
    "Files = os.listdir(DataFolder)\n",
    "ixi_ids = [int(f[3:6]) for f in Files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d77b1-8355-486b-8544-33fa62dc81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(CSVPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986f33d-0e12-4bac-9212-c3da0f9d4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "model.eval()\n",
    "idx = 15\n",
    "Pred = []\n",
    "Acct = []\n",
    "for idx in range(len(Files)):\n",
    "    filename = Files[idx]\n",
    "    file_path = os.path.join(DataFolder, filename)\n",
    "    img = nib.load(file_path)\n",
    "    x_np = img.get_fdata().astype(np.float32)       # avoid float64 bloat\n",
    "    x_tn = torch.from_numpy(x_np).unsqueeze(0).to(device).float()\n",
    "    # print(type(inputvolume), inputvolume.device, inputvolume.shape)\n",
    "    \n",
    "    # print(x_tn.shape)\n",
    "    \n",
    "    _id = int(filename[3:6])\n",
    "    AGE = df[df['IXI_ID']==_id]['AGE'].values[0]\n",
    "    \n",
    "    inputvolume = x_tn.to(device).type(torch.FloatTensor)\n",
    "    with torch.no_grad():\n",
    "        output, (attn1, attn2, attn3) = model(inputvolume, return_attention_weights=True)\n",
    "    Predicted_Age = output.item()\n",
    "    Pred.append(Predicted_Age)\n",
    "    Acct.append(AGE)\n",
    "    \n",
    "    print(Predicted_Age, AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbff98a-8e17-4b63-b848-c202a795ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae = np.mean(np.abs(np.array(Pred) - np.array(Acct)))\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdd868-bf9a-41e6-b6e7-228a933250ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
