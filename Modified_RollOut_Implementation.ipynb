{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04495be6-7f43-4e09-8cff-21fc05d62be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from Models.MultiViewViT import MultiViewViT\n",
    "from load_data import IMG_Folder\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ddf6ac4-bbc0-4527-8ec0-5ee672e2ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init(w):\n",
    "    classname = w.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        if hasattr(w, 'weight'):\n",
    "            # nn.init.kaiming_normal_(w.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(w.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "                nn.init.constant_(w.bias, 0)\n",
    "    if classname.find('Linear') != -1:\n",
    "        if hasattr(w, 'weight'):\n",
    "            torch.nn.init.xavier_normal_(w.weight)\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        if hasattr(w, 'weight') and w.weight is not None:\n",
    "            nn.init.constant_(w.weight, 1)\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "            nn.init.constant_(w.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71a109b-af58-419d-b796-e239f838f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = MultiViewViT(\n",
    "    image_sizes=[(91, 109), (91, 91), (109, 91)],\n",
    "    patch_sizes=[(7, 7), (7, 7), (7, 7)],\n",
    "    num_channals=[91, 109, 91],\n",
    "    vit_args={\n",
    "        'emb_dim': 768, 'mlp_dim': 3072, 'num_heads': 12,\n",
    "        'num_layers': 12, 'num_classes': 1,\n",
    "        'dropout_rate': 0.1, 'attn_dropout_rate': 0.0\n",
    "    },\n",
    "    mlp_dims=[3, 128, 256, 512, 1024, 512, 256, 128, 1]\n",
    ")\n",
    "model.apply(weights_init)\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "# Load checkpoint\n",
    "CheckpointPath = r'C:\\Users\\Rishabh\\training_output_metricsMulti_VIT_best_model.pth.tar'\n",
    "checkpoint = torch.load(CheckpointPath, map_location=\"cpu\")\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4aee4cb-1ca9-4139-9ab8-bc135a48b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckpointPath = r'C:\\Users\\Rishabh\\trainingMulti_VIT_best_model.pth.tar'\n",
    "CSVPath = r'C:\\Users\\Rishabh\\Documents\\TransBTS\\IXI.xlsx'\n",
    "DataFolder = r'C:\\Users\\Rishabh\\Documents\\TrimeseData'\n",
    "test_data = IMG_Folder(CSVPath, DataFolder)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38edbc95-1a57-4c4c-a9b3-54d00af30bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(test_data\n",
    "                                         ,batch_size=1\n",
    "                                         ,num_workers=0\n",
    "                                         ,pin_memory=True\n",
    "                                         ,drop_last=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f50a832-9a75-431f-bf07-08e96f4713c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions = []       # [B,H,T,T] per layer (forward)\n",
    "attention_grads = []  # [B,H,T,T] per layer (backward)\n",
    "\n",
    "def hook_attn_probs(module, inp, out):\n",
    "    # out might be probs or (ctx, probs) depending on your code\n",
    "    probs = out[1] if isinstance(out, (tuple, list)) else out\n",
    "    attentions.append(probs)                    # DO NOT detach if you want grads\n",
    "    probs.register_hook(lambda g: attention_grads.append(g))  # tensor-level grad hook\n",
    "\n",
    "# Register on each block's attention where probs exist\n",
    "for blk in model.vit_1.transformer.encoder_layers:\n",
    "    blk.attn.register_forward_hook(hook_attn_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cf5bc-0068-4626-b168-00b9021e16cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 91, 109, 91])\n",
      "tensor([[35.0340]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "out, targ, ID, Attn1, Attn2, Attn3 = [], [], [], [], [], []\n",
    "target_numpy, predicted_numpy, ID_numpy = [], [], []\n",
    "model.eval()\n",
    "for _, (input, ids ,target,male) in enumerate(valid_loader):\n",
    "\n",
    "    input = input.to(device).type(torch.FloatTensor)\n",
    "    print(input.shape)\n",
    "    output, (attn1, attn2, attn3) = model(input, return_attention_weights=True)\n",
    "    print(output)\n",
    "    output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e4b8a-2b46-4296-bf25-4a9905a8ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputvolume = []\n",
    "for _, (input, ids ,target,male) in enumerate(valid_loader):\n",
    "\n",
    "    inputvolume = input.to(device).type(torch.FloatTensor)\n",
    "    print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb48c3-a0a1-4e82-b2db-359d02941c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attn = torch.stack(attentions)\n",
    "AttnGr = torch.stack(attention_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0241e-1140-475d-ad4a-1dcba279541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attn.shape, AttnGr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7066b-2497-4642-b589-0ca560651fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attn = torch.mean(Attn, dim=0)\n",
    "AttnGr = torch.mean(AttnGr, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8557f-17ef-461c-81cd-775d6c4f4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attentions),  len(attention_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ece02f-f702-4f14-af0d-d964b830036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions[0].shape, attention_grads[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16269f0-4511-49f7-b7ce-ed4bcd8ff1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions = torch.mean(torch.stack(attentions), dim=0)\n",
    "attention_grads = torch.mean(torch.stack(attention_grads), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0492eff-d4e6-4a21-aef0-7d3c474a49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions.shape, attention_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca011a-2772-4bba-8c22-93346c9440f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions = attentions.mean(dim=0)\n",
    "attention_grads = attention_grads.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21f3cd-13b5-45d6-a873-041ce1626da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(attentions.detach().numpy(), cmap='hot')  # mask is your 2D NumPy array\n",
    "plt.colorbar(label='Attention intensity')\n",
    "plt.title('Attention Map')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008de99-daa1-4d38-b1b0-81d618168aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(attention_grads.detach().numpy(), cmap='hot')  # mask is your 2D NumPy array\n",
    "plt.colorbar(label='Attention intensity')\n",
    "plt.title('Attention Map')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc2c69-069f-483a-b3d5-e62fe114ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa007d4-0e75-423b-8c7d-3f0b03ba4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def grad_rollout(attentions, gradients, discard_ratio):\n",
    "    result = torch.eye(attentions[0].size(-1))\n",
    "    with torch.no_grad():\n",
    "        for attention, grad in zip(attentions, gradients):                \n",
    "            weights = grad\n",
    "            attention_heads_fused = attention*weights\n",
    "            print(attention_heads_fused.shape)\n",
    "            attention_heads_fused = attention_heads_fused.mean(axis=1)\n",
    "            attention_heads_fused[attention_heads_fused < 0] = 0\n",
    "\n",
    "            # Drop the lowest attentions, but\n",
    "            # don't drop the class token\n",
    "            flat = attention_heads_fused.view(attention_heads_fused.size(0), -1)\n",
    "            _, indices = flat.topk(int(flat.size(-1)*discard_ratio), -1, False)\n",
    "            #indices = indices[indices != 0]\n",
    "            flat[0, indices] = 0\n",
    "\n",
    "            I = torch.eye(attention_heads_fused.size(-1))\n",
    "            a = (attention_heads_fused + 1.0*I)/2\n",
    "            a = a / a.sum(dim=-1)\n",
    "            result = torch.matmul(a, result)\n",
    "    \n",
    "    # Look at the total attention between the class token,\n",
    "    # and the image patches\n",
    "    return result\n",
    "    mask = result[0, 0 , 1 :]\n",
    "    # In case of 224x224 image, this brings us from 196 to 14\n",
    "    width = int(mask.size(-1)**0.5)\n",
    "    mask = mask.reshape(width, width).numpy()\n",
    "    mask = mask / np.max(mask)\n",
    "    return mask    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7b086-d8fc-45eb-90c4-65336c783e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix1 = torch.randn(12, 196, 196)  # 5×5 random floats\n",
    "matrix2 = torch.randn(12, 196, 196)  # 5×5 random floats\n",
    "matrix1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486781a2-de86-4231-9d08-93ab4ffe8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grad_rollout(Attn, AttnGr, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4758b-ade8-4399-9765-831f4f930a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = result[0,1:]\n",
    "width = int(mask.size(-1)**0.5)\n",
    "print(width)\n",
    "# mask = mask.reshape(width, width).numpy()\n",
    "mask = mask.reshape(15, 13).numpy()\n",
    "mask = mask / np.max(mask)\n",
    "mask.shape, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d7f4f-026d-48a1-acdc-54a97aa0635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.resize(mask, (109, 91))\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3aeb6-175a-4637-a1bf-e342bd9b1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(mask, cmap='hot')  # mask is your 2D NumPy array\n",
    "# plt.colorbar(label='Attention intensity')\n",
    "# plt.title('Attention Map')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fa5d1-2c85-4775-9099-c9bad0097745",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputvolume.shape\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(np.array(inputvolume[0,:,:,25]))  # mask is your 2D NumPy array\n",
    "# plt.colorbar(label='Attention intensity')\n",
    "# plt.title('Attention Map')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "inputvolume[0,:,:,15].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0b662-6811-46a6-a766-2af40b65977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "15*13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa3aca-95cc-4c8b-960a-19fa3f0d96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3bcb6-3d56-47aa-b74e-837ae0930d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(Attn.detach().numpy()[5], cmap='hot')  # mask is your 2D NumPy array\n",
    "plt.colorbar(label='Attention intensity')\n",
    "plt.title('Attention Map')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bfaeb-8825-4cf9-a26a-856b9248e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(AttnGr.detach().numpy()[10], cmap='hot')  # mask is your 2D NumPy array\n",
    "plt.colorbar(label='Attention intensity')\n",
    "plt.title('Attention Map')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9ab0f1-4d9b-46c1-8edf-1fc980116a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AttnGr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74109ef8-1dfc-43be-9c81-7886285c8757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
