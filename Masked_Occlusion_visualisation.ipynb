{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009beee-4364-4c63-92af-79798653276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from Models.MultiViewViT import MultiViewViT\n",
    "from load_data import IMG_Folder\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "from nilearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67092cc-404d-4368-8184-56cb66ab5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(w):\n",
    "    classname = w.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        if hasattr(w, 'weight'):\n",
    "            # nn.init.kaiming_normal_(w.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(w.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "                nn.init.constant_(w.bias, 0)\n",
    "    if classname.find('Linear') != -1:\n",
    "        if hasattr(w, 'weight'):\n",
    "            torch.nn.init.xavier_normal_(w.weight)\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        if hasattr(w, 'weight') and w.weight is not None:\n",
    "            nn.init.constant_(w.weight, 1)\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "            nn.init.constant_(w.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c701434-3657-48ce-b813-61565bb9637d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = MultiViewViT(\n",
    "    image_sizes=[(91, 109), (91, 91), (109, 91)],\n",
    "    patch_sizes=[(7, 7), (7, 7), (7, 7)],\n",
    "    num_channals=[91, 109, 91],\n",
    "    vit_args={\n",
    "        'emb_dim': 768, 'mlp_dim': 3072, 'num_heads': 12,\n",
    "        'num_layers': 12, 'num_classes': 1,\n",
    "        'dropout_rate': 0.1, 'attn_dropout_rate': 0.0\n",
    "    },\n",
    "    mlp_dims=[3, 128, 256, 512, 1024, 512, 256, 128, 1]\n",
    ")\n",
    "model.apply(weights_init)\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "# Load checkpoint\n",
    "CheckpointPath = r'C:\\Users\\Rishabh\\training_output_metricsMulti_VIT_best_model.pth.tar'\n",
    "checkpoint = torch.load(CheckpointPath, map_location=\"cpu\")\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a358f45-3e19-4b7d-8fb1-3d6e4407ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckpointPath = r'C:\\Users\\Rishabh\\trainingMulti_VIT_best_model.pth.tar'\n",
    "CSVPath = r'C:\\Users\\Rishabh\\Documents\\TransBTS\\IXI.xlsx'\n",
    "DataFolder = r'C:\\Users\\Rishabh\\Documents\\TrimeseData'\n",
    "Files = os.listdir(DataFolder)\n",
    "test_data = IMG_Folder(CSVPath, DataFolder)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1c038-4fb0-4777-92a2-00df2c894e2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ======== Load AAL atlas ======== #\n",
    "aal_atlas = datasets.fetch_atlas_aal()\n",
    "atlas_filename = aal_atlas.maps\n",
    "atlas_nii = nib.load(atlas_filename)\n",
    "atlas_data = atlas_nii.get_fdata()\n",
    "region_labels = np.unique(atlas_data)[1:]  # Exclude 0 (background)\n",
    "region_mapping = {code: label for code, label in zip(region_labels, aal_atlas.labels)}\n",
    "\n",
    "print(f\"Number of regions in atlas: {len(region_labels)}\")\n",
    "print(f\"Atlas shape: {atlas_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168816d-dcca-4abc-9b2c-7e0b6f1f2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample image to determine exact shape\n",
    "for sample_data in valid_loader:\n",
    "    sample_img = sample_data[0]\n",
    "    img_shape = (sample_img.shape[1], sample_img.shape[2], sample_img.shape[3])\n",
    "    print(f\"Detected image shape: {img_shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a3f52-673b-44a6-b833-ab56422989a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d242b324-a001-4fca-91b2-5a62a6af211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white0(image, threshold=0):\n",
    "    \"\"\"\n",
    "    Standardize voxels with value > threshold\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        threshold: Threshold value\n",
    "\n",
    "    Returns:\n",
    "        Standardized image\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    mask = (image > threshold).astype(int)\n",
    "\n",
    "    # Vectorized implementation to avoid unnecessary memory allocation\n",
    "    image_h = image * mask\n",
    "\n",
    "    # Calculate mean and std only for relevant voxels\n",
    "    non_zero_voxels = np.sum(mask)\n",
    "    if non_zero_voxels > 0:\n",
    "        mean = np.sum(image_h) / non_zero_voxels\n",
    "\n",
    "        # More memory efficient way to calculate std\n",
    "        std_sum = np.sum((image_h - mean * mask) ** 2)\n",
    "        std = np.sqrt(std_sum / non_zero_voxels)\n",
    "\n",
    "        if std > 0:\n",
    "            normalized = mask * (image - mean) / std\n",
    "            # Use in-place operations to reduce memory usage\n",
    "            image = normalized + image * (1 - mask)\n",
    "            return image\n",
    "\n",
    "    # Default case\n",
    "    return np.zeros_like(image, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8e900-f375-4638-bff3-f27177687263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "model.eval()\n",
    "idx = 15\n",
    "filename = Files[idx]\n",
    "file_path = os.path.join(DataFolder, filename)\n",
    "img = nib.load(file_path)\n",
    "x_np = img.get_fdata(caching='unchanged').astype(np.float32)       # avoid float64 bloat\n",
    "\n",
    "inputvolume = white0(x_np)\n",
    "inputvolume = torch.from_numpy(inputvolume).unsqueeze(0).to(device).float()\n",
    "inputvolume = inputvolume.to(device).type(torch.FloatTensor)\n",
    "output = model(inputvolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5d3f9-e878-4857-9c42-1116e19d1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np.shape, inputvolume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66bf1d-2092-4b22-acde-5dd87992ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e730a-73dc-473c-8986-d7630c4c2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a657f1-658d-4ff0-928a-728f5ce60b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mask = (atlas_data == region_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273292cd-ce3e-4e75-91e9-aba0ac45b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mask.shape, np.unique(region_mask[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae089391-66aa-4748-ba17-e2af669b2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: create a random 2D numpy array\n",
    "img = region_mask[30,:,:]\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(img)   # you can use \"gray\", \"jet\", etc.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976ac4a-df9a-4c06-9842-ba994bd142b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: create a random 2D numpy array\n",
    "img = x_np[30,:,:]\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(img)   # you can use \"gray\", \"jet\", etc.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a789fb-4cdb-468f-9581-e8e98a9b312e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21e414-26f2-4663-bc27-b5ce21d04c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab928e-0e81-4cb4-9de8-f3ca457508eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
