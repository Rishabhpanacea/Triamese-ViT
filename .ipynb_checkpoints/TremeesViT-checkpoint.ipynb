{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6550ea-12d6-4337-be6b-834c54c4cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from Models.MultiViewViT import MultiViewViT\n",
    "from load_data import IMG_Folder\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd4c4c-a238-4f01-8f21-5a0cefa0bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init(w):\n",
    "    classname = w.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        if hasattr(w, 'weight'):\n",
    "            # nn.init.kaiming_normal_(w.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(w.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "                nn.init.constant_(w.bias, 0)\n",
    "    if classname.find('Linear') != -1:\n",
    "        if hasattr(w, 'weight'):\n",
    "            torch.nn.init.xavier_normal_(w.weight)\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        if hasattr(w, 'weight') and w.weight is not None:\n",
    "            nn.init.constant_(w.weight, 1)\n",
    "        if hasattr(w, 'bias') and w.bias is not None:\n",
    "            nn.init.constant_(w.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5cf1c-e1e0-4e25-a710-945094cc1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = MultiViewViT(\n",
    "    image_sizes=[(91, 109), (91, 91), (109, 91)],\n",
    "    patch_sizes=[(7, 7), (7, 7), (7, 7)],\n",
    "    num_channals=[91, 109, 91],\n",
    "    vit_args={\n",
    "        'emb_dim': 768, 'mlp_dim': 3072, 'num_heads': 12,\n",
    "        'num_layers': 12, 'num_classes': 1,\n",
    "        'dropout_rate': 0.1, 'attn_dropout_rate': 0.0\n",
    "    },\n",
    "    mlp_dims=[3, 128, 256, 512, 1024, 512, 256, 128, 1]\n",
    ")\n",
    "model.apply(weights_init)\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "# Load checkpoint\n",
    "CheckpointPath = r'C:\\Users\\Rishabh\\training_output_metricsMulti_VIT_best_model.pth.tar'\n",
    "checkpoint = torch.load(CheckpointPath, map_location=\"cpu\")\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73eee3-e519-480f-a3f0-cde9071d465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckpointPath = r'C:\\Users\\Rishabh\\trainingMulti_VIT_best_model.pth.tar'\n",
    "CSVPath = r'C:\\Users\\Rishabh\\Documents\\TransBTS\\IXI.xlsx'\n",
    "DataFolder = r'C:\\Users\\Rishabh\\Documents\\TrimeseData'\n",
    "test_data = IMG_Folder(CSVPath, DataFolder)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4868f0-20cf-4d7f-8ad1-b1dbaf1d4159",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(test_data\n",
    "                                         ,batch_size=1\n",
    "                                         ,num_workers=0\n",
    "                                         ,pin_memory=True\n",
    "                                         ,drop_last=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7789b-593b-4dd6-aef7-0bd33fc85f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "513/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641bdaa-ad9d-4eb4-9a82-a7add86ed29a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "out, targ, ID, Attn1, Attn2, Attn3 = [], [], [], [], [], []\n",
    "target_numpy, predicted_numpy, ID_numpy = [], [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for _, (input, ids ,target,male) in enumerate(valid_loader):\n",
    "        # print('ids:- ', ids)\n",
    "        # print('input:- ', input.shape)\n",
    "        # print('target:- ', target)\n",
    "        # print('male:- ', male)\n",
    "        \n",
    "        input = input.to(device).type(torch.FloatTensor)\n",
    "        \n",
    "        # ======= convert male lable to one hot type ======= #\n",
    "        # male = torch.unsqueeze(male,1)\n",
    "        # male = torch.zeros(male.shape[0],2).scatter_(1,male,1)\n",
    "        # male = male.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        target = torch.from_numpy(np.expand_dims(target,axis=1))\n",
    "        target = target.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        # ======= compute output and loss ======= #\n",
    "        output, (attn1, attn2, attn3) = model(input, return_attention_weights=True)\n",
    "        out.append(output.cpu().numpy())\n",
    "        targ.append(target.cpu().numpy())\n",
    "        ID.append(ids)\n",
    "        attn1= torch.stack(attn1, dim=0)\n",
    "        attn2 = torch.stack(attn2, dim=0)\n",
    "        attn3 = torch.stack(attn3, dim=0)\n",
    "        print('attn1 shape:- ', attn1.shape)\n",
    "        print('attn2 shape:- ', attn2.shape)\n",
    "        print('attn3 shape:- ', attn3.shape)\n",
    "        attn1_mean = attn1.mean(dim=0)\n",
    "        attn2_mean = attn2.mean(dim=0)\n",
    "        attn3_mean = attn3.mean(dim=0)\n",
    "        avg_attn1 = attn1_mean.mean(dim=1)\n",
    "        avg_attn2 = attn2_mean.mean(dim=1)\n",
    "        avg_attn3 = attn3_mean.mean(dim=1)\n",
    "        avg_attn1 = avg_attn1.mean(dim=0)\n",
    "        avg_attn2 = avg_attn2.mean(dim=0)\n",
    "        avg_attn3 = avg_attn3.mean(dim=0)\n",
    "        Attn1.append(avg_attn1)\n",
    "        Attn2.append(avg_attn2)\n",
    "        Attn3.append(avg_attn3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d73d48-c264-4ef5-a824-273e979f20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attn1 = torch.mean(torch.stack(Attn1), dim=0)\n",
    "Attn2 = torch.mean(torch.stack(Attn2), dim=0)\n",
    "Attn3 = torch.mean(torch.stack(Attn3), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb0312-953d-4c84-9c86-ad18669640bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attn1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3501c8-96bd-4548-9030-90ee3a10f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attn2[0].shape, len(Attn2), avg_attn1.shape, len(attn1), attn1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac6f32-9340-470c-a389-f1ee7e33f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(len(v))\n",
    "# mask = v.reshape(15, 13).detach().numpy()  # Attn1\n",
    "mask = v.reshape(13, 13).detach().numpy()\n",
    "mask = cv2.resize(mask / mask.max(), (91, 109))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa47afc-2d00-40e4-af58-6005b2f542f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_attentions.shape, aug_att_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe561c2-e658-4d11-9901-319a7b627858",
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3575e0-f798-4144-8a18-c11133cc3c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "13*13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9f686-6c0d-41bb-a621-d286532f73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example 2D array\n",
    "array2d = mask\n",
    "\n",
    "plt.imshow(array2d, cmap='viridis')  # You can change cmap to 'gray', 'hot', etc.\n",
    "plt.colorbar()  # Adds color scale legend\n",
    "plt.title(\"2D Array Plot\")\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac3580-c4e7-480b-946f-7da644dd45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "DataFolder = r'C:\\Users\\Rishabh\\Documents\\TrimeseData'\n",
    "Files = os.listdir(DataFolder)\n",
    "indx = 29\n",
    "img = nib.load(os.path.join(DataFolder, Files[indx]))\n",
    "\n",
    "data = img.get_fdata()  \n",
    "print(\"Data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01403d1-9c09-4993-ba0b-c06f9b1b7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "idx = 17\n",
    "im = data[idx, :, :]\n",
    "result = (mask * im).astype(np.uint8)\n",
    "\n",
    "# Plotting the two images side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axs[0].imshow(im, cmap='gray')\n",
    "axs[0].set_title(\"Original Slice\")\n",
    "axs[0].axis('off')\n",
    "fig.colorbar(axs[0].imshow(im, cmap='gray'), ax=axs[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "axs[1].imshow(result, cmap='gray')\n",
    "axs[1].set_title(\"Masked Slice\")\n",
    "axs[1].axis('off')\n",
    "fig.colorbar(axs[1].imshow(result, cmap='gray'), ax=axs[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2da797-9092-4cfd-99c1-896545860310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
